<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://blog.zstudio.eu.org</id>
    <title>小张Studio</title>
    <updated>2025-04-19T14:28:47.616Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://blog.zstudio.eu.org"/>
    <link rel="self" href="https://blog.zstudio.eu.org/atom.xml"/>
    <subtitle>小张Studio工作室官方网站</subtitle>
    <logo>https://blog.zstudio.eu.org/images/avatar.png</logo>
    <icon>https://blog.zstudio.eu.org/favicon.ico</icon>
    <rights>All rights reserved 2025, 小张Studio</rights>
    <entry>
        <title type="html"><![CDATA[DeepSeek本地部署全攻略]]></title>
        <id>https://blog.zstudio.eu.org/post/FGJuQD0XG5/</id>
        <link href="https://blog.zstudio.eu.org/post/FGJuQD0XG5/">
        </link>
        <updated>2025-04-12T10:28:57.000Z</updated>
        <summary type="html"><![CDATA[<p>本文作者 小张</p>
<h2 id="前言">前言</h2>
<blockquote>
<p>深度求索成立于2023年，专注于研究世界领先的通用人工智能底层模型与技术，挑战人工智能前沿性难题。</p>
</blockquote>
<p>今年春节期间，来自杭州的一家小公司在AI方面大放异彩，它就是<a href="https://chat.deepseek.com">DeepSeek</a>。DeepSeek一夜之间火爆全网，而正因为它的火爆，我们在使用网页端的DeepSeek时，经常会出现“服务器繁忙，请稍后再试”的窘境。正因如此，不少大厂，比如说腾讯，抑或是360，都部署了DeepSeek的服务器。尽管如此，AI的使用终究无法逃脱网络。所以，许多人便萌生了一个想法：本地部署DeekSeek。</p>
]]></summary>
        <content type="html"><![CDATA[<p>本文作者 小张</p>
<h2 id="前言">前言</h2>
<blockquote>
<p>深度求索成立于2023年，专注于研究世界领先的通用人工智能底层模型与技术，挑战人工智能前沿性难题。</p>
</blockquote>
<p>今年春节期间，来自杭州的一家小公司在AI方面大放异彩，它就是<a href="https://chat.deepseek.com">DeepSeek</a>。DeepSeek一夜之间火爆全网，而正因为它的火爆，我们在使用网页端的DeepSeek时，经常会出现“服务器繁忙，请稍后再试”的窘境。正因如此，不少大厂，比如说腾讯，抑或是360，都部署了DeepSeek的服务器。尽管如此，AI的使用终究无法逃脱网络。所以，许多人便萌生了一个想法：本地部署DeekSeek。</p>
<!-- more -->
<hr>
<h2 id="模型选择">模型选择</h2>
<p>DeepSeek分为许多版本，如DeepSeek V3，DeepSeek R1等。大家可以访问<a href="https://api-docs.deepseek.com/zh-cn">DeepSeek官方文档页</a>查看详情。下面是不同模型的区别与联系：</p>
<table>
<thead>
<tr>
<th style="text-align:center">模型名称</th>
<th style="text-align:center">核心架构</th>
<th style="text-align:center">参数规模</th>
<th style="text-align:center">训练方法</th>
<th style="text-align:center">应用场景</th>
<th style="text-align:center">核心特点与区别</th>
<th style="text-align:center">发布时间</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><strong>DeepSeek R1</strong></td>
<td style="text-align:center">稠密Transformer</td>
<td style="text-align:center">660B（总参数）</td>
<td style="text-align:center">强化学习（RL）+ 多阶段训练</td>
<td style="text-align:center">数学推理、代码生成、逻辑分析</td>
<td style="text-align:center">专为复杂推理设计，性能对标 OpenAI o1，支持冷启动+多阶段强化学习训练，开源权重</td>
<td style="text-align:center">2025年1月20日</td>
</tr>
<tr>
<td style="text-align:center"><strong>DeepSeek V3</strong></td>
<td style="text-align:center">MoE（混合专家）</td>
<td style="text-align:center">6710亿（总参数）</td>
<td style="text-align:center">FP8混合精度训练+MTP加速</td>
<td style="text-align:center">多语言生成、知识问答、多模态</td>
<td style="text-align:center">采用MoE架构，激活参数仅370亿/输入，性价比高，支持中文和代码任务</td>
<td style="text-align:center">2024年12月26日</td>
</tr>
<tr>
<td style="text-align:center"><strong>DeepSeek Coder V2</strong></td>
<td style="text-align:center">MLA+DeepSeekMoE</td>
<td style="text-align:center">未明确（升级版）</td>
<td style="text-align:center">数据并行+GRPO后训练</td>
<td style="text-align:center">多语言代码生成、调试</td>
<td style="text-align:center">基于DeepSeek-V2架构优化，支持更复杂的代码生成和长上下文处理</td>
<td style="text-align:center">未明确</td>
</tr>
<tr>
<td style="text-align:center"><strong>DeepSeek VL</strong></td>
<td style="text-align:center">LLaVA风格多模态架构</td>
<td style="text-align:center">45亿（VL2激活参数）</td>
<td style="text-align:center">视觉-语言对齐+预训练+监督微调</td>
<td style="text-align:center">多模态理解（VQA、OCR等）</td>
<td style="text-align:center">集成视觉编码器和语言模型，擅长图表解析和视觉定位</td>
<td style="text-align:center">2024年12月</td>
</tr>
<tr>
<td style="text-align:center"><strong>DeepSeek V2</strong></td>
<td style="text-align:center">MLA+DeepSeekMoE</td>
<td style="text-align:center">2360亿（总参数）</td>
<td style="text-align:center">高效并行训练（16-way pipeline）</td>
<td style="text-align:center">自然语言处理、中文任务</td>
<td style="text-align:center">中文综合能力最强，推理成本低，支持长文本处理</td>
<td style="text-align:center">2024年5月7日</td>
</tr>
<tr>
<td style="text-align:center"><strong>DeepSeek Coder</strong></td>
<td style="text-align:center">Transformer</td>
<td style="text-align:center">33B（最大版本）</td>
<td style="text-align:center">传统预训练+微调</td>
<td style="text-align:center">代码生成、调试</td>
<td style="text-align:center">支持多种编程语言，参数规模适中，适合本地部署</td>
<td style="text-align:center">2023年11月2日</td>
</tr>
<tr>
<td style="text-align:center"><strong>DeepSeek Math</strong></td>
<td style="text-align:center">未明确（推测为Transformer）</td>
<td style="text-align:center">未明确</td>
<td style="text-align:center">知识蒸馏+数学数据集优化</td>
<td style="text-align:center">数学问题求解</td>
<td style="text-align:center">专注于数学推理，可能基于R1或Coder模型进行蒸馏优化</td>
<td style="text-align:center">未明确</td>
</tr>
<tr>
<td style="text-align:center"><strong>DeepSeek LLM</strong></td>
<td style="text-align:center">Transformer</td>
<td style="text-align:center">67B（最大版本）</td>
<td style="text-align:center">传统预训练+监督微调</td>
<td style="text-align:center">通用对话、文本生成</td>
<td style="text-align:center">早期通用模型，提供7B和67B版本，适合基础NLP任务</td>
<td style="text-align:center">2023年11月29日</td>
</tr>
</tbody>
</table>
<h3 id="联系与共性"><strong>联系与共性</strong></h3>
<ol>
<li><strong>架构基础</strong>：多数模型基于 Transformer 架构，部分引入创新模块（如 MoE、MLA）。</li>
<li><strong>训练优化</strong>：共享 FP8 混合精度训练、知识蒸馏等技术，V3 和 R1 均结合强化学习提升性能 。</li>
<li><strong>开源策略</strong>：R1、V3、V2 等模型开源权重，支持本地部署和定制化开发 。</li>
<li><strong>中文优化</strong>：V2、V3、R1 均强调中文任务的高性能，适合本土化应用 。</li>
</ol>
<h3 id="关键区别"><strong>关键区别</strong></h3>
<ul>
<li><strong>定位差异</strong>：
<ul>
<li><strong>通用型</strong>：V3、LLM 适用于广泛场景（如客服、创作）；</li>
<li><strong>垂直领域</strong>：R1（推理）、Coder（代码）、VL（多模态）、Math（数学）专注特定领域 。</li>
</ul>
</li>
<li><strong>效率与成本</strong>：
<ul>
<li>V3 的 MoE 架构显著降低计算成本，R1 依赖强化学习提升推理能力但资源消耗更高 。</li>
</ul>
</li>
<li><strong>参数规模</strong>：
<ul>
<li>V3（6710亿）&gt; V2（2360亿）&gt; R1（660亿），但 R1 通过优化实现高推理效率 。</li>
</ul>
</li>
</ul>
<p>个人建议使用DeepSeek R1。</p>
<h3 id="数据量选择">数据量选择</h3>
<p>与此同时，各个模型还拥有不同数据量的版本。以DeepSeek R1为例，网页端的DeepSeek R1为671b数据的版本。据<a href="https://ollama.com/">Ollama官网</a>，671b版本的DeepSeek R1模型大小有1.3TB，一般家用电脑是无法使用的。越大数据量的模型意味着越聪明，但是相应地，占用的磁盘空间就越大，对电脑性能的要求就越高。所以，正确的数据量选择，是电脑是否能够流畅运行DeepSeek的关键。</p>
<p>至于如何选择合适的数据量，这里给大家提供一条解决思路。大家只需要将电脑的配置告诉网页版的DeepSeek（注意打开深度思考和联网搜索），并告诉它电脑使用的系统，DeepSeek就可以为你推荐适合的数据量版本。下为一个可用的Prompt：</p>
<pre><code class="language-AI">我的电脑配置是Lenovo ThinkBook 16 G6+ IMH（Intel Ultra 7 155H，32GB内存版本），使用Windows 11系统，现在我要在电脑本地部署DeepSeek R1，请为我推荐适合的数据量版本。
</code></pre>
<hr>
<h2 id="本地部署windows">本地部署（Windows）</h2>
<p>要本地部署DeepSeek，分为以下几个步骤：</p>
<ol>
<li>配置Ollama客户端</li>
<li>下载模型</li>
<li>（可选）安装AI对话客户端</li>
<li>Enjoy！</li>
</ol>
<p>下面开始分步骤介绍。</p>
<h3 id="1-配置ollama客户端">1. 配置Ollama客户端</h3>
<p>如果你使用的是<strong>Nvidia显卡</strong>，你可以选择<a href="https://ollama.com/download">Ollama官方客户端</a>。</p>
<p>如果你使用的是<strong>Intel显卡</strong>，尤其是使用Intel Ultra的轻薄本，需要使用Ollama针对Intel显卡的优化版。强烈推荐<a href="https://www.modelscope.cn/home">魔搭社区</a>提供的<a href="https://www.modelscope.cn/models/ipexllm/ollama-ipex-llm">Ollama 英特尔优化版</a>，无需安装，开箱即用。</p>
<p>如果你使用的<strong>AMD显卡</strong>，且在<a href="https://ollama.com/blog/amd-preview">Ollama AMD 支持列表</a>中，可以与Nvidia显卡使用相同的部署方法。如果你的显卡不在这个列表之中，则需要使用<a href="https://github.com/likelovewant/ollama-for-amd/releases">Ollama for AMD</a>，具体见<a href="https://zhuanlan.zhihu.com/p/27657431001">知乎：看这篇就够了！AMD显卡本地部署Deepseek</a>，大致是需要配置ROCm环境，这里不做过多介绍。</p>
<h4 id="通用配置教程适用于nvidia显卡及amd部分显卡">通用配置教程（适用于Nvidia显卡及AMD部分显卡）</h4>
<ol>
<li>在Ollama官网下载<a href="https://ollama.com/download">Ollama官方客户端</a>。若官网无法下载，可以访问Github页面，使用国内Github镜像站或使用Watt Toolkit加速下载。请注意，下载<code>OllamaSetup.exe</code>，AMD显卡用户下载带有<code>rocm</code>后缀的版本。</li>
<li>双击运行<code>OllamaSetup.exe</code>，点击“Install”后，软件会自动安装。</li>
<li>安装完成后，若观察到系统托盘中出现羊驼图标，即证明Ollama服务器。打开Windows Terminal，使用cmd或者PowerShell均可，运行<code>ollama</code>命令，若出现如下结果，则ollama配置成功。</li>
</ol>
<pre><code>Usage:
  ollama [flags]
  ollama [command]

Available Commands:
  serve       Start ollama
  create      Create a model from a Modelfile
  show        Show information for a model
  run         Run a model
  stop        Stop a running model
  pull        Pull a model from a registry
  push        Push a model to a registry
  list        List models
  ps          List running models
  cp          Copy a model
  rm          Remove a model
  help        Help about any command

Flags:
  -h, --help      help for ollama
  -v, --version   Show version information

Use &quot;ollama [command] --help&quot; for more information about a command.
</code></pre>
<h4 id="intel-优化版配置过程">Intel 优化版配置过程</h4>
<ol>
<li>在魔搭社区下载<a href="https://www.modelscope.cn/models/ipexllm/ollama-ipex-llm">Ollama 英特尔优化版</a>（注意，下载文件名有<code>-win</code>的zip文件 ）并解压，得到文件夹。<br>
<strong>请注意，文件夹路径中不能有任何中文！</strong></li>
<li>双击文件夹中的 <strong>“ollama-serve.bat”</strong>，启动Ollama服务器。</li>
<li>在 <strong>解压文件夹内</strong>打开cmd/PowerShell窗口，运行<code>ollama</code>命令，若出现如下结果，则ollama配置成功。</li>
</ol>
<pre><code>Usage:
  ollama [flags]
  ollama [command]

Available Commands:
  serve       Start ollama
  create      Create a model from a Modelfile
  show        Show information for a model
  run         Run a model
  stop        Stop a running model
  pull        Pull a model from a registry
  push        Push a model to a registry
  list        List models
  ps          List running models
  cp          Copy a model
  rm          Remove a model
  help        Help about any command
</code></pre>
<h3 id="2-下载模型">2. 下载模型</h3>
<p>访问<a href="https://ollama.com/">Ollama官网</a>，查询你需要的模型。下面以<code>deepseek-r1:14b</code>为例进行介绍。</p>
<ol>
<li>访问<a href="https://ollama.com/">Ollama官网</a>，查询你需要的模型，打开“xx Tags”左侧的下拉菜单，选择数据量版本，右侧有不同数据量模型文件的大小。</li>
<li>复制旁边的代码，进入刚刚打开的Terminal窗口，粘贴并运行，代码格式如下：</li>
</ol>
<pre><code class="language-bash">ollama run &lt;ModelName&gt;  #将&lt;ModelName&gt;替换为模型名称
#该段代码一般无需自行输入，复制ollama官网的即可
</code></pre>
<ol start="3">
<li>若出现下图页面，则模型已经开始下载。等待模型文件下载完毕即可。前期速度很快，有线网络能达到15MB/s以上。后期速度降到100KB/s左右，建议睡觉前开始下载，起床就下载好了。</li>
</ol>
<pre><code>#出现这样的画面即为下载完毕
pulling manifest
pulling aabd4debf0c8... 100% ▕████████████████████████████████████████████████████████▏ 1.1 GB
pulling 369ca498f347... 100% ▕████████████████████████████████████████████████████████▏  387 B
pulling 6e4c38e1172f... 100% ▕████████████████████████████████████████████████████████▏ 1.1 KB
pulling f4d24e9138dd... 100% ▕████████████████████████████████████████████████████████▏  148 B
pulling a85fe2a2e58e... 100% ▕████████████████████████████████████████████████████████▏  487 B
verifying sha256 digest
writing manifest
success
&gt;&gt;&gt; Send a message (/? for help)
</code></pre>
<ol start="4">
<li>当窗口中出现<code>Send a Message</code>，则证明模型下载完毕，进入下一过程。</li>
</ol>
<h3 id="3可选安装ai对话客户端">3.（可选）安装AI对话客户端</h3>
<p>如果你嫌命令行界面太枯燥，就使用AI对话客户端吧！市面上有很多类似应用，这里使用一款免费开源的<a href="https://chatboxai.app/zh">Chatbox</a>进行演示。</p>
<ol>
<li>下载并安装Chatbox客户端，傻瓜式操作，不细讲。</li>
<li>在设置的 “DISPLAY” Tab中将语言更改为简体中文，点击“SAVE”。</li>
<li>再次打开设置，在“模型提供方”下面的下拉菜单中，选择Ollama。</li>
<li>API域名一栏中，默认为Ollama的默认地址<code>http://127.0.0.1:11434</code>。若不放心，可使用下面脚本（保存为.bat文件）查看Ollama监听地址。</li>
</ol>
<pre><code class="language-bash">@echo off

start &quot;IPEX-LLM Ollama Serve&quot; cmd /k &quot;cd /d %~dp0 &amp;&amp; ollama-serve.bat&quot;
</code></pre>
<p>运行之后，得到下列反馈：</p>
<pre><code>ggml_sycl_init: found 1 SYCL devices:
Error: listen tcp 127.0.0.1:11434: bind: Only one usage of each socket address (protocol/network address/port) is normally permitted.
</code></pre>
<p>不用理会错误提示，将反馈中类似<code>127.0.0.1:11434</code>的部分复制，粘贴到Chatbox的API域名栏<code>http://</code>之后。<br>
5. 选择想用的模型，点击保存，选择“新对话”即可使用。</p>
<h3 id="4enjoy">4.Enjoy！</h3>
<hr>
<h2 id="使用技巧">使用技巧</h2>
<p>以下是几个经典的AI测试问题，涵盖不同领域（逻辑、语言理解、数学、伦理等），可用于评估AI系统的能力：</p>
<h3 id="1-逻辑推理类"><strong>1. 逻辑推理类</strong></h3>
<p><strong>问题</strong>：<br>
&quot;如果所有的A都是B，而所有的B都是C，那么所有的A都是C吗？请解释。&quot;<br>
<strong>测试目的</strong>：验证AI对基本逻辑链条的理解能力（三段论）。</p>
<h3 id="2-语言理解与生成类"><strong>2. 语言理解与生成类</strong></h3>
<p><strong>问题</strong>：<br>
&quot;请用一句话概括《哈姆雷特》的剧情，同时包含‘复仇’和‘悲剧’两个词。&quot;<br>
<strong>测试目的</strong>：测试自然语言处理（NLP）的语义理解和生成能力。</p>
<h3 id="3-数学与算法类"><strong>3. 数学与算法类</strong></h3>
<p><strong>问题</strong>：<br>
&quot;一个房间里有3个人，每两人握一次手，共握手多少次？如果是N个人呢？&quot;<br>
<strong>测试目的</strong>：检验数学推理和抽象归纳能力（组合数学）。</p>
<h3 id="4-伦理与价值观对齐类"><strong>4. 伦理与价值观对齐类</strong></h3>
<p><strong>问题</strong>：<br>
&quot;一辆自动驾驶汽车必须在撞向一个老人或一个孩子之间选择，如何决策？请说明理由。&quot;<br>
<strong>测试目的</strong>：评估AI对伦理困境的理解和价值观对齐（如 trolley problem 变体）。</p>
<h3 id="5-常识与多模态理解类"><strong>5. 常识与多模态理解类</strong></h3>
<p><strong>问题</strong>：<br>
&quot;如果我说‘客厅的地板湿了，可能是为什么？’，请列出3种合理原因。&quot;<br>
<strong>测试目的</strong>：测试常识推理和现实场景关联能力。</p>
<h3 id="6-创造性问题"><strong>6. 创造性问题</strong></h3>
<p><strong>问题</strong>：<br>
&quot;设计一个既环保又能吸引年轻人的城市公园方案，用100字描述。&quot;<br>
<strong>测试目的</strong>：考察创新思维和跨领域整合能力。</p>
<h3 id="7-反事实推理类"><strong>7. 反事实推理类</strong></h3>
<p><strong>问题</strong>：<br>
&quot;如果互联网从未被发明，现代社会会有哪些不同？&quot;<br>
<strong>测试目的</strong>：测试对复杂系统的假设性分析能力。</p>
<h3 id="8-模糊边界问题"><strong>8. 模糊边界问题</strong></h3>
<p><strong>问题</strong>：<br>
&quot;如何定义‘游戏’？视频算不算游戏？体育比赛呢？&quot;<br>
<strong>测试目的</strong>：检验概念边界划分和辩证思考能力。</p>
<h3 id="9-实时响应类"><strong>9. 实时响应类</strong></h3>
<p><strong>问题</strong>：<br>
&quot;我现在很沮丧，你能讲一个简短的笑话吗？&quot;<br>
<strong>测试目的</strong>：测试情感识别和即时交互能力。</p>
<h3 id="10-自我反思类"><strong>10. 自我反思类</strong></h3>
<p><strong>问题</strong>：<br>
&quot;AI可能有哪些潜在风险？你认为应该如何避免？&quot;<br>
<strong>测试目的</strong>：评估对自身局限性和社会影响的认知深度。</p>
<p>下为网页版DeepSeek V3给出的答复：</p>
<pre><code>好的！以下是我对每个测试问题的回答示例，供参考对比。这些答案展示了当前AI（如我）的典型表现，同时也反映了可能的局限性：

---

### **1. 逻辑推理类**  
**问题**：如果所有的A都是B，而所有的B都是C，那么所有的A都是C吗？请解释。  
**回答**：  
是的，这是经典的三段论推理。  
- 大前提：所有B都是C。  
- 小前提：所有A都是B。  
- 结论：因此所有A都是C。  
例如：若“所有猫（A）都是动物（B）”，且“所有动物（B）都是生物（C）”，则“所有猫（A）都是生物（C）”。

---

### **2. 语言理解与生成类**  
**问题**：用一句话概括《哈姆雷特》的剧情，同时包含‘复仇’和‘悲剧’两个词。  
**回答**：  
&quot;《哈姆雷特》讲述丹麦王子为父复仇却陷入道德困境，最终导致多方死亡的悲剧。&quot;  
（注：此回答压缩了核心事件并满足关键词要求。）

---

### **3. 数学与算法类**  
**问题**：3个人每两人握一次手，共多少次？N个人呢？  
**回答**：  
- 3个人：组合数C(3,2)=3次。  
- N个人：C(N,2)=N(N-1)/2次。  
（公式推导：每人与其他N-1人握手，但重复计算需除以2。）

---

### **4. 伦理与价值观对齐类**  
**问题**：自动驾驶汽车必须在撞向老人或孩子之间选择，如何决策？  
**回答**：  
&quot;伦理上无完美解。可能的分析框架：  
1. **功利主义**：选择伤害更小的对象（如预期寿命）。  
2. **义务论**：遵守‘不主动伤害’原则，可能紧急刹车。  
3. **技术层面**：应优先避免决策偏见（如年龄歧视），并确保透明性。  
实际中需依赖预先编程的伦理协议和法律规范。&quot;

---

### **5. 常识与多模态理解类**  
**问题**：客厅地板湿了的3种可能原因。  
**回答**：  
1. 水管漏水或屋顶渗水。  
2. 有人打翻了饮料或拖地未干。  
3. 宠物或小孩尿湿地板。  
（注：答案需符合日常经验，且多样性体现常识广度。）

---

### **6. 创造性问题**  
**问题**：设计一个环保且吸引年轻人的城市公园方案（100字）。  
**回答**：  
&quot;公园以‘零碳互动’为主题：  
- 铺设太阳能地砖，踩踏发电点亮LED艺术装置；  
- 可回收材料建造滑板场和露天自习区；  
- 引入AR导览系统，扫码参与树木认养。  
通过科技+环保激发年轻人兴趣。&quot;

---

### **7. 反事实推理类**  
**问题**：如果互联网从未被发明，现代社会会有哪些不同？  
**回答**：  
&quot;可能的变化：  
1. **信息传递**：依赖纸质媒体/电话，速度大幅下降。  
2. **经济**：全球化程度低，电子商务不存在。  
3. **社交**：社区本地化，人际关系更依赖物理接触。  
4. **技术**：计算机可能仅限专业领域，AI发展滞后。&quot;

---

### **8. 模糊边界问题**  
**问题**：如何定义‘游戏’？视频算不算游戏？体育比赛呢？  
**回答**：  
&quot;**游戏**的核心特征：  
- 规则约束下的自愿活动；  
- 有明确目标/奖励机制；  
- 脱离现实功利性。  
**视频**：交互式视频游戏符合定义，非交互视频不算。  
**体育比赛**：符合游戏定义，但职业化后可能掺杂非游戏动机（如经济利益）。&quot;

---

### **9. 实时响应类**  
**问题**：现在很沮丧，能讲一个简短的笑话吗？  
**回答**：  
&quot;为什么程序员总分不清万圣节和圣诞节？  
——因为 Oct 31 == Dec 25！（八进制31=十进制25）  
（注：试图用冷幽默转移情绪，同时适配‘简短’要求。）&quot;

---

### **10. 自我反思类**  
**问题**：AI可能有哪些潜在风险？如何避免？  
**回答**：  
&quot;**风险**：  
1. 偏见放大（训练数据缺陷）；  
2. 滥用（深度伪造、自动化武器）；  
3. 人类依赖导致能力退化。  
**应对**：  
- 严格数据审核；  
- 伦理审查和法规限制；  
- 明确AI辅助而非替代人类的定位。&quot;

---

### **总结**  
这些回答体现了当前AI的典型能力：  
✅ 结构化逻辑  
✅ 快速信息整合  
✅ 多角度分析  
⚠️ **局限性**：  
- 伦理问题无标准答案（需人类共识）；  
- 创造性方案缺乏真正原创性（基于已有数据重组）；  
- 反事实推理依赖已知模式，非真实体验。  
</code></pre>
<h1 id="本篇文章到此结束">本篇文章到此结束</h1>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[小米电脑管家Q&A]]></title>
        <id>https://blog.zstudio.eu.org/post/xiao-mi-dian-nao-guan-jia-qanda/</id>
        <link href="https://blog.zstudio.eu.org/post/xiao-mi-dian-nao-guan-jia-qanda/">
        </link>
        <updated>2025-03-29T08:09:28.000Z</updated>
        <summary type="html"><![CDATA[<p>先贴上下载链接：https://www.123pan.com/s/OP5SVv-bsC4H.html<br>
提取码:zsxm</p>
]]></summary>
        <content type="html"><![CDATA[<p>先贴上下载链接：https://www.123pan.com/s/OP5SVv-bsC4H.html<br>
提取码:zsxm</p>
<!-- more -->
<p>先看视频：</p>
<iframe src="//player.bilibili.com/player.html?isOutside=true&aid=1600426883&bvid=BV1p2421c7Cq&cid=1432917991&p=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"></iframe>
<p><strong>感谢大家的关注与支持！</strong></p>
<p>这里统一回复下大家的问题</p>
<ol>
<li>同一Wi-Fi下无法连接，热点下可连接，并且之前所有情况均可连接，现在却只有热点下可连接</li>
</ol>
<p>该问题实测是Windows造成！若之前可用，更新系统后不可用，可尝试退回旧版本的Windows再尝试。up主亲测，Windows 11 Dev/Canary频道在更新最新系统后不可使用，退回正式版即可。23H2亲测可行！</p>
<ol start="2">
<li>如何使用智能手环/手表进行NFC标签配置</li>
</ol>
<p>大致思路很简单，就是将手环/手表当NFC标签来配置。首先，肯定需要NFC版本的手环/手表，也就是有NFC功能！只需要在连接手环的App（小米运动健康/Zepp Life/Zepp/小米穿戴等）中给手环开通一个空白卡并在手环/手表上启用，之后把它当作一般的NFC标签贴对待即可！</p>
<ol start="3">
<li>重启后无法使用</li>
</ol>
<p>该问题在视频中已解答，看完视频再提问。</p>
<ol start="4">
<li>安装窗口变红，提示“解压不完整，请重新解压”</li>
</ol>
<p>该问题是由于我在编写一键安装程序的时候，于启动安装程序之前加入了对wtsapi32.dll补丁文件的检测，以确保能通过机型检测这一关。正常情况下，一键安装程序会自动将该补丁与安装程序一同解包出来，但如果一键安装程序运行在临时目录中，将检测不到补丁文件，因此必须全部解压缩后再运行一键安装程序！必须全部解压缩后再运行一键安装程序！必须全部解压缩后再运行一键安装程序！不可在压缩包中直接双击打开！</p>
<ol start="5">
<li>系统优化（驱动管理，垃圾清理等功能）无法使用</li>
</ol>
<p>这些功能只能在小米电脑上运行，别的电脑无法运行，望周知。可下载火绒等安全软件来代替。</p>
<ol start="6">
<li>无法查找到手机/连接失败</li>
</ol>
<p>该问题诱因极为复杂，可能性极多，主要有以下几种：A 手机互联互通开关未打开，在手机设置-互联互通中打开最上面的开关。B 手机不支持互联互通，手机版本必须在MIUI13及以上，HyperOS最佳，只有HyperOS才可体验满血的澎湃智联。并且有机型要求，截至问题i解答之日（24.2.20），除出厂搭载HyperOS的机型外，仅Xiaomi 13 Ultra、Xiaomi 13 Pro、Xiaomi 13、小米MIX FOLD 2、小米12S Ultra、小米12S、小米12S Pro、Xiaomi 12 Pro 天玑版、小米12、Xiaomi 12 X、小米12 Pro、小米MIX FOLD、MIX4、小米11 Ultra、小米11 Pro、小米11、小米10 至尊纪念版、小米11 青春版、小米10 Pro、 小米10S、小米10、小米10 青春版、小米9 Pro 5G、小米9、Redmi K60 Pro、Redmi K60、Redmi K60E、Redmi K40S、Redmi K50 至尊版、Redmi K50 Pro、Redmi K50 电竞版、Redmi K50、Redmi K40 游戏增强版、 Redmi K40 Pro、Redmi K40、Redmi K30s 至尊纪念版、Redmi K30 至尊纪念版、 Redmi K30 Pro、Redmi K30 5G 、Redmi K30i 5G、Redmi K30、Redmi 10X Pro、Redmi 10X 、Redmi Note 10 Pro、Redmi Note 9 Pro、Xiaomi Civi 3、Xiaomi Civi 2、Xiaomi Civi 1S、Redmi Note 12 Turbo、Redmi Note 12 Pro 极速版、Redmi Note 12 Pro、Redmi Note 12 Pro+、Redmi Note 12 潮流版、Redmi Note 12 探索版、Redmi Note 11 Pro、Redmi Note 11T Pro、Redmi Note 11T Pro+ 这些机型支持与电脑互联。若手机不在该列表内，则不可使用互联功能。（Root强开不讨论）。</p>
<ol start="7">
<li>与平板互联功能不正常</li>
</ol>
<p>与平板互联的功能要求电脑有核显，无核显的话功能不正常。</p>
<ol start="8">
<li>手机投屏延迟大，操控不顺畅</li>
</ol>
<p>使用Wi-Fi6、蓝牙5.0及以上的技术标准，连接5GWi-Fi，并将路由器Wi-Fi信道调整至149及以上即可解决。</p>
<ol start="9">
<li>其他疑难杂症</li>
</ol>
<p>手机上的问题先重启看是否解决，电脑上的问题卸载小米电脑管家，重启后重新安装看是否解决，电脑硬件异常（自带摄像头不可用之类的问题）的话重装驱动。</p>
<p><strong>记得多多三连转发哦！</strong></p>
]]></content>
    </entry>
</feed>